{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-88b83a0deb95>, line 115)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-88b83a0deb95>\"\u001b[0;36m, line \u001b[0;32m115\u001b[0m\n\u001b[0;31m    model.eval()\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#coding:utf8\n",
    "from config_point import opt\n",
    "import os\n",
    "import torch as t\n",
    "import models\n",
    "from utils import box_util\n",
    "from data_point.dataset import KittiPoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from utils.train_util import *\n",
    "from utils.visualize import Visualizer\n",
    "from utils.data_util import *\n",
    "from utils.train_util import *\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as T\n",
    "from tensorboardX import SummaryWriter\n",
    "import math\n",
    "    \n",
    "def train(**kwargs):\n",
    "    opt.parse(kwargs)\n",
    "    dev = ToDevice(opt) # init\n",
    "    writer = SummaryWriter(opt.env+'/train')\n",
    "    writer_val = SummaryWriter(opt.env+'/val')\n",
    "\n",
    "    # step1: data\n",
    "    train_data = KittiPoint(root=opt.root,sets_type='val',white_list=opt.white_list,\n",
    "                               rotate_to_center=True, random_flip=True, random_shift=True, one_hot=True)\n",
    "    val_data = KittiPoint(root=opt.root,sets_type='val',white_list=opt.white_list,\n",
    "                          rotate_to_center=True, one_hot=True)\n",
    "    train_dataloader = DataLoader(train_data,opt.batch_size,shuffle=True,num_workers=opt.num_workers)\n",
    "    val_dataloader = DataLoader(val_data,opt.batch_size_val,shuffle=False,num_workers=opt.num_workers)\n",
    "    \n",
    "    # step2: configure model\n",
    "    model = getattr(models, opt.model)() # test_img_only!!! experiment_no_depth ; (num_out=2)\n",
    "    model = dev.trans(model)[0]\n",
    "    if opt.load_model_path:\n",
    "        model.load(opt.load_model_path)\n",
    "    \n",
    "    # step3: criterion and optimizer\n",
    "    crossEp = t.nn.CrossEntropyLoss()\n",
    "    smoothL1 = t.nn.SmoothL1Loss() # !!! loss need to be determined match output & label\n",
    "    optimizer = t.optim.Adam(model.parameters(), lr=opt.lr, weight_decay=opt.weight_decay)\n",
    "        \n",
    "    # step4: meters；lm; lm_ry_cls,lm_ry_res,cm_ry； lm_size_cls,lm_size_res,cm_size; lm_loc\n",
    "    previous_loss = 1e100\n",
    "    lm = LossMeter(total=True,ry=True,size=True,loc=True)\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(opt.max_epoch):\n",
    "        # init meter\n",
    "        lm.reset(total=True,ry=True,size=True,loc=True) # init meter ; train_data)/opt.batch_size\n",
    "        batch_num = len(train_dataloader)\n",
    "        # each batch\n",
    "        for ii,(in_pc,in_center,in_rot,in_vec, loc,ry_cls,ry_res,size_cls,size_res) \\\n",
    "                in tqdm(enumerate(train_dataloader),total=batch_num):\n",
    "            # 记得改train的dataset 从val变回train\n",
    "            [in_pc,in_center,in_rot,in_vec] = dev.trans(in_pc,in_center,in_rot,in_vec) # BCHW\n",
    "            # 分类gt必须为1维  torch.Size([bsize]) 而不是torch.Size([bsize，1])\n",
    "            [loc,ry_cls,ry_res,size_cls,size_res] = \\\n",
    "                dev.trans(loc,ry_cls.squeeze(1),ry_res,size_cls.squeeze(1),size_res)# label\n",
    "            # train\n",
    "            optimizer.zero_grad()\n",
    "            out_loc,out_ry_cls,out_ry_res,out_size_cls,out_size_res = model(in_pc,in_vec)\n",
    "            \n",
    "            loss_loc = smoothL1(out_loc+in_center,loc)\n",
    "            loss_ry_cls = crossEp(out_ry_cls,ry_cls) # output(BxNum)不需要加softmax, label(B)不需要为onehot\n",
    "            loss_ry_res = smoothL1(out_ry_res,ry_res)\n",
    "            loss_size_cls = crossEp(out_size_cls,size_cls)\n",
    "            loss_size_res = smoothL1(out_size_res,size_res)\n",
    "            loss = loss_loc + loss_ry_cls + loss_ry_res + loss_size_cls + loss_size_res \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # meters update and visualize; lm = LossMeter\n",
    "            lm.lm_add(loss, loss_ry_cls,loss_ry_res, loss_size_cls,loss_size_res, loss_loc) # train_loss\n",
    "            # print('out_ry_cls',out_ry_cls,ry_cls)\n",
    "            out_ry_cls = t.argmax(out_ry_cls,1)\n",
    "            out_size_cls = t.argmax(out_size_cls,1)\n",
    "            lm.cm_add(out_ry_cls,ry_cls, out_size_cls,size_cls) #可以均为NxK维，也可均为一维真值\n",
    "            # print('cfm',out_ry_cls, ry_cls, sep='\\n')\n",
    "            if ii%opt.print_freq==opt.print_freq-1:\n",
    "                lm.print_log(loss, loss_ry_cls,loss_ry_res, loss_size_cls,loss_ry_res, loss_loc)\n",
    "            if ii%opt.plot_freq==opt.plot_freq-1:\n",
    "                niter = epoch * batch_num + ii # training step; batch_num is always same\n",
    "                lm.plot(writer,niter, total=True,ry=True,size=True,loc=True)\n",
    "                \n",
    "        # validate and visualize; lossMeter_val, benchmark_val\n",
    "        lm_val, bm_val = val(model,val_dataloader,device,writer_val,niter,epoch)\n",
    "        # aos_val, cm_ry_val, iou_val, iou_bev_val \n",
    "        if opt.save_model and (bm_val.aos > 0.9 or bm_val.iou_3d>0.7):\n",
    "            model.save()\n",
    "        # benchmark & lossmeter\n",
    "        lm_val.plot(writer_val,niter, total=True,ry=True,size=True,loc=True) # curve obout val\n",
    "        bm_val.plot(writer_val,niter, aos=True, iou_3d=True, iou_bev=True)\n",
    "        bm_val.print_log(aos=True, iou_3d=True, iou_bev=True)\n",
    "        # write text; print confusion_matrix:ry & size\n",
    "        print_epoch_info(writer,epoch,niter, lr, lm,lm_val, bm_val)\n",
    "        # update learning rate\n",
    "        if lm.value()[0].item() > previous_loss: # .item change tensor to float         \n",
    "            lr = lr * opt.lr_decay\n",
    "            # 第二种降低学习率的方法:不会有moment等信息的丢失\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        previous_loss = lm.value()[0].item()\n",
    "        # if epoch < 5:\n",
    "            # lr = lr * 0.5\n",
    "            # for param_group in optimizer.param_groups:\n",
    "                # param_group['lr'] = lr\n",
    "    # model.save()\n",
    "    print('Finishe training & save model')\n",
    "\n",
    "def val(model,dataloader,dev,writer_val,niter,epoch):\n",
    "    '''\n",
    "    计算模型在验证集上的准确率等信息\n",
    "    '''\n",
    "    print('Evaluation of epoch:{} with batch_num:{}'.format(epoch,len(dataloader))\n",
    "    model.eval()\n",
    "    lm_val = LossMeter(total=True,ry=True,size=True,loc=True)\n",
    "    bm_val = Benchmark(aos=True, iou_3d=True, iou_bev=True)\n",
    "    \n",
    "    crossEp = t.nn.CrossEntropyLoss()\n",
    "    smoothL1 = t.nn.SmoothL1Loss() # !!! loss need to be determined match output & label\n",
    "          \n",
    "    for ii, (in_pc,in_center,in_rot,in_vec, loc,ry_cls,ry_res,size_cls,size_res) in enumerate(dataloader):\n",
    "        with t.no_grad():\n",
    "            [in_pc,in_center, in_rot, in_vec] = dev.trans(in_pc,in_center, in_rot, in_vec) # BCHW\n",
    "            [loc, ry_cls,ry_res, size_cls,size_res] = \\\n",
    "                dev.trans(loc, ry_cls.squeeze(1),ry_res, size_cls.squeeze(1),size_res)# label\n",
    "            \n",
    "            out_loc, out_ry_cls,out_ry_res, out_size_cls,out_size_res = model(in_pc,in_vec)\n",
    "            \n",
    "            loss_loc = smoothL1(out_loc+in_center,loc)\n",
    "            loss_ry_cls = crossEp(out_ry_cls,ry_cls) # output(BxNum)不需要加softmax, label(B)不需要为onehot\n",
    "            loss_ry_res = smoothL1(out_ry_res,ry_res)\n",
    "            loss_size_cls = crossEp(out_size_cls,size_cls)\n",
    "            loss_size_res = smoothL1(out_size_res,size_res)\n",
    "            loss = loss_loc + loss_ry_cls + loss_ry_res + loss_size_cls + loss_size_res \n",
    "            \n",
    "            lm_val.lm_add(loss, loss_ry_cls,loss_ry_res, loss_size_cls,loss_size_res, loss_loc) # train_loss\n",
    "            out_ry_cls = t.argmax(out_ry_cls,1)\n",
    "            out_size_cls = t.argmax(out_size_cls,1)\n",
    "            lm_val.cm_add(out_ry_cls, ry_cls, out_size_cls,size_cls) #可以均为NxK维，也可均为一维真值\n",
    "            \n",
    "            bsize = loc.shape[0] # num\n",
    "            for i in range(bsize):\n",
    "                out_ry = class2angle(out_ry_cls[i].item(), out_ry_res[i].item())\n",
    "                ry = class2angle(ry_cls[i].item(), ry_res[i].item())\n",
    "                out_size = class2size(out_size_cls[i].itemm(), out_size_res[i].item())\n",
    "                size = class2size(size_cls[i].item(), size_res[i],item())\n",
    "                # size = hwl\n",
    "                size_p, ry_p, loc_p = tuple(out_size[i].tolist()), out_ry, tuple(out_loc[i].tolist()) # predict\n",
    "                size_g, ry_g, loc_g = tuple(size[i].tolist()), ry, tuple(loc[i].tolist()) # groundtruth\n",
    "                iou_3d, iou_bev = box_util.call_iou_compute_3d((size_g, ry_g, loc_g),(size_p, ry_p, loc_p))\n",
    "                \n",
    "                aos = (1+math.cos(out_ry-ry)) / 2\n",
    "                bm_val.add(aos, iou_3d,iou_bev) # recall of aos =1; bev=bird eye's view\n",
    "    model.train()\n",
    "    return lm_val, bm_val\n",
    "    \n",
    "\n",
    "def help():\n",
    "    '''\n",
    "    打印帮助的信息： python file.py help\n",
    "    '''\n",
    "    print('''\n",
    "    usage : python file.py <function> [--args=value]\n",
    "    <function> := train | test | help\n",
    "    example: \n",
    "            python {0} train --env='env0701' --lr=0.01\n",
    "            python {0} test --dataset='path/to/dataset/root/'\n",
    "            python {0} help\n",
    "    avaiable args:'''.format(__file__))\n",
    "    # from inspect import getsource\n",
    "    # source = (getsource(opt.__class__))\n",
    "    # print(source)\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "#     import fire\n",
    "#     fire.Fire()\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
