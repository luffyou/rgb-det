{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6076acb802ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# # #print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointSIFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m     \u001b[0mxyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6076acb802ad>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPointSIFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_pointsift\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ------------------------ modules ------------------------ #\n",
    "def conv_bn(inp, oup, kernel, stride=1, activation='relu'):\n",
    "    seq = nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, kernel, stride),\n",
    "        nn.BatchNorm2d(oup)\n",
    "    )\n",
    "    if activation == 'relu':\n",
    "        seq.add_module('2', nn.ReLU())\n",
    "    return seq\n",
    "\n",
    "\n",
    "def fc_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(inp, oup),\n",
    "        nn.BatchNorm1d(oup),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape=None):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.size()\n",
    "        if self.shape is None:  # 为x增加一个channel维度，并且num_channel=1\n",
    "            return x.view((size[0], 1) + size[1:])\n",
    "        return x.contiguous().view(tuple([size[0], ]) + tuple(self.shape))\n",
    "\n",
    "\n",
    "class Matmul(nn.Module):\n",
    "    def __init__(self, weights, bias=None):\n",
    "        super(Matmul, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.bias is None:\n",
    "            return torch.matmul(x, self.weights)\n",
    "        return torch.matmul(x, self.weights) + self.bias\n",
    "\n",
    "\n",
    "class Input_transform_net(nn.Module):\n",
    "    \"\"\" Input (XYZ) Transform Net, input is BxNx3 gray image\n",
    "        Return:\n",
    "            Transformation matrix of size 3xK \"\"\"\n",
    "\n",
    "    def __init__(self, config, K=3):\n",
    "        super(Input_transform_net, self).__init__()\n",
    "        self.num_point = config.num_point\n",
    "        self.transform_xyz_weights = nn.Parameter(torch.zeros(256, 3 * K))\n",
    "        self.transform_xyz_bias = nn.Parameter(torch.zeros(3 * K) + torch.FloatTensor(np.eye(3).flatten()))\n",
    "\n",
    "        self.num_features = 0\n",
    "        self.net = nn.Sequential(\n",
    "            Reshape(),\n",
    "            conv_bn(1, 64, [1, 3]),\n",
    "            conv_bn(64, 128, [1, 1]),\n",
    "            conv_bn(128, 1024, [1, 1]),\n",
    "            nn.MaxPool2d([self.num_point, 1]),\n",
    "            Reshape([-1, ]),\n",
    "            fc_bn(1024, 512),\n",
    "            fc_bn(512, 256),\n",
    "            Matmul(self.transform_xyz_weights, self.transform_xyz_bias),\n",
    "            Reshape([3, K])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Feature_transform_net(nn.Module):\n",
    "    \"\"\" Feature Transform Net, input is Bx64xN*1\n",
    "        Return:\n",
    "            Transformation matrix of size KxK \"\"\"\n",
    "\n",
    "    def __init__(self, config, K=64):\n",
    "        super(Feature_transform_net, self).__init__()\n",
    "        self.num_point = config.num_point\n",
    "\n",
    "        self.transform_feat_weights = nn.Parameter(torch.zeros(256, K * K))\n",
    "        self.transform_feat_bias = nn.Parameter(torch.zeros(K * K) + torch.FloatTensor(np.eye(K).flatten()))\n",
    "\n",
    "        self.num_features = 0\n",
    "        self.net = nn.Sequential(\n",
    "            conv_bn(64, 64, [1, 1]),\n",
    "            conv_bn(64, 128, [1, 1]),\n",
    "            conv_bn(128, 1024, [1, 1]),\n",
    "            nn.MaxPool2d([self.num_point, 1]),\n",
    "            Reshape([-1, ]),\n",
    "            fc_bn(1024, 512),\n",
    "            fc_bn(512, 256),\n",
    "            Matmul(self.transform_feat_weights, self.transform_feat_bias),\n",
    "            Reshape([K, K])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class PointNet_SA_module_basic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNet_SA_module_basic, self).__init__()\n",
    "\n",
    "    def index_points(self, points, idx):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            this function select the specific points from the whole points according to the idx.\n",
    "        Input:\n",
    "            points: input points data, [B, N, C]\n",
    "            idx: sample index data, [B, D1, D2, ..., Dn]\n",
    "        Return:\n",
    "            new_points:, indexed points data, [B, D1, D2, ..., Dn, C]\n",
    "        \"\"\"\n",
    "        device = points.device\n",
    "        B = points.shape[0]\n",
    "        view_shape = list(idx.shape)\n",
    "        view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "        repeat_shape = list(idx.shape)\n",
    "        repeat_shape[0] = 1\n",
    "        batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "        new_points = points[batch_indices, idx, :]\n",
    "        return new_points\n",
    "\n",
    "    def square_distance(self, src, dst):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            just the simple Euclidean distance fomula，(x-y)^2,\n",
    "        Input:\n",
    "            src: source points, [B, N, C]\n",
    "            dst: target points, [B, M, C]\n",
    "        Output:\n",
    "            dist: per-point square distance, [B, N, M]\n",
    "        \"\"\"\n",
    "        B, N, _ = src.shape\n",
    "        _, M, _ = dst.shape\n",
    "        dist = -2 * torch.matmul(src, dst.permute(0, 2, 1).contiguous())\n",
    "        dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "        dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "        return dist\n",
    "\n",
    "    def farthest_point_sample(self, xyz, npoint):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            first we choose a point from the point set randomly, at the same time,\n",
    "            see it as a centroid.the calculate the distance of the point and any others,\n",
    "            and choose the farthest as the second centroid.\n",
    "            repeat until the number of choosed point has arrived npoint.\n",
    "        Input:\n",
    "            xyz: pointcloud data, [B, N, C]\n",
    "            npoint: number of samples\n",
    "        Return:\n",
    "            centroids: the index sampled pointcloud data, [B, npoint, C]\n",
    "        \"\"\"\n",
    "        device = xyz.device\n",
    "        B, N, C = xyz.shape\n",
    "        Np = npoint\n",
    "        centroids = torch.zeros(B, Np, dtype=torch.long).to(device)\n",
    "        distance = torch.ones(B, N).to(device) * 1e10\n",
    "        farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "        batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "        for i in range(Np):\n",
    "            centroids[:, i] = farthest\n",
    "            centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "            dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "            mask = dist < distance\n",
    "            distance[mask] = dist[mask]\n",
    "            farthest = torch.max(distance, -1)[1]\n",
    "        return centroids\n",
    "\n",
    "    def farthest_point_sample_uniform(self, xyz, npoint):\n",
    "        \"\"\"\n",
    "           Description:\n",
    "                different with the front function.the function choose the next centroid by\n",
    "                calculate the distance of one point with other centroids, rather than other point.\n",
    "                finally, get the max distance.\n",
    "           Input:\n",
    "               xyz: pointcloud data, [B, N, C]\n",
    "               npoint: number of samples\n",
    "           Return:\n",
    "               centroids: sampled pointcloud data, [B, npoint, C]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def knn(self, xyz, npoint):\n",
    "        \"\"\"\n",
    "           Description:\n",
    "               first we choose a point from the point set randomly, at the same time,\n",
    "               see it as a centroid.the calculate the distance of the point and any others,\n",
    "               and choose the farthest as the second centroid.\n",
    "               repeat until the number of choosed point has arrived npoint.\n",
    "           Input:\n",
    "               xyz: pointcloud data, [B, N, C]\n",
    "               npoint: number of samples\n",
    "           Return:\n",
    "               centroids: sampled pointcloud data, [B, npoint, C]\n",
    "       \"\"\"\n",
    "        pass\n",
    "\n",
    "    def ball_query(self, radius, nsample, xyz, new_xyz):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            radius: local region radius\n",
    "            nsample: max sample number in local region\n",
    "            xyz: all points, [B, N, C]\n",
    "            new_xyz: query points, [B, Np, C]\n",
    "        Return:\n",
    "            group_idx: grouped points index, [B, Np, Ns]\n",
    "        \"\"\"\n",
    "        device = xyz.device\n",
    "        B, N, C = xyz.shape\n",
    "        _, Np, _ = new_xyz.shape\n",
    "        Ns = nsample\n",
    "        group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, Np, 1])\n",
    "        sqrdists = self.square_distance(new_xyz, xyz)\n",
    "        group_idx[sqrdists > radius ** 2] = N\n",
    "        group_idx = group_idx.sort(dim=-1)[0][:, :, :Ns]\n",
    "        group_first = group_idx[:, :, 0].view(B, Np, 1).repeat([1, 1, Ns])\n",
    "        mask = group_idx == N\n",
    "        group_idx[mask] = group_first[mask]\n",
    "        return group_idx\n",
    "\n",
    "    def sample_and_group(self, npoint, radius, nsample, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            npoint: the number of points that make the local region.\n",
    "            radius: the radius of the local region\n",
    "            nsample: the number of points in a local region\n",
    "            xyz: input points position data, [B, N, C]\n",
    "            points: input points data, [B, N, D]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, 1, C]\n",
    "            new_points: sampled points data, [B, 1, N, C+D]\n",
    "        \"\"\"\n",
    "        B, N, C = xyz.shape\n",
    "        Np = npoint\n",
    "        assert isinstance(Np, int)\n",
    "\n",
    "        new_xyz = self.index_points(xyz, self.farthest_point_sample(xyz, npoint))\n",
    "        idx = self.ball_query(radius, nsample, xyz, new_xyz)\n",
    "        grouped_xyz = self.index_points(xyz, idx)\n",
    "        grouped_xyz -= new_xyz.view(B, Np, 1, C)  # the points of each group will be normalized with their centroid\n",
    "        if points is not None:\n",
    "            grouped_points = self.index_points(points, idx)\n",
    "            new_points = torch.cat([grouped_xyz, grouped_points], dim=-1)\n",
    "        else:\n",
    "            new_points = grouped_xyz\n",
    "        return new_xyz, new_points\n",
    "\n",
    "    def sample_and_group_all(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Equivalent to sample_and_group with npoint=1, radius=np.inf, and the centroid is (0, 0, 0)\n",
    "        Input:\n",
    "            xyz: input points position data, [B, N, C]\n",
    "            points: input points data, [B, N, D]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, 1, C]\n",
    "            new_points: sampled points data, [B, 1, N, C+D]\n",
    "        \"\"\"\n",
    "        device = xyz.device\n",
    "        B, N, C = xyz.shape\n",
    "        new_xyz = torch.zeros(B, 1, C).to(device)\n",
    "        grouped_xyz = xyz.view(B, 1, N, C)\n",
    "        if points is not None:\n",
    "            new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)\n",
    "        else:\n",
    "            new_points = grouped_xyz\n",
    "        return new_xyz, new_points\n",
    "\n",
    "\n",
    "class Pointnet_SA_module(PointNet_SA_module_basic):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
    "\n",
    "        super(Pointnet_SA_module, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.group_all = group_all\n",
    "\n",
    "        self.conv_bns = nn.Sequential()\n",
    "        in_channel += 3  # +3是因为points 与 xyz concat的原因\n",
    "        for i, out_channel in enumerate(mlp):\n",
    "            m = conv_bn(in_channel, out_channel, 1)\n",
    "            self.conv_bns.add_module(str(i), m)\n",
    "            in_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: the shape is [B, N, 3]\n",
    "            points: thes shape is [B, N, D], the data include the feature infomation\n",
    "        Return:\n",
    "            new_xyz: the shape is [B, Np, 3]\n",
    "            new_points: the shape is [B, Np, D']\n",
    "        \"\"\"\n",
    "\n",
    "        if self.group_all:\n",
    "            new_xyz, new_points = self.sample_and_group_all(xyz, points)\n",
    "        else:\n",
    "            new_xyz, new_points = self.sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
    "        new_points = new_points.permute(0, 3, 1, 2).contiguous()  # change size to (B, C, Np, Ns), adaptive to conv\n",
    "        # print(\"1:\", new_points.shape)\n",
    "        new_points = self.conv_bns(new_points)\n",
    "        # print(\"2:\", new_points.shape)\n",
    "        new_points = torch.max(new_points, 3)[0]  # 取一个local region里所有sampled point特征对应位置的最大值。\n",
    "\n",
    "        new_points = new_points.permute(0, 2, 1).contiguous()\n",
    "        # print(new_points.shape)\n",
    "        return new_xyz, new_points\n",
    "\n",
    "\n",
    "class Pointnet_SA_MSG_module(PointNet_SA_module_basic):\n",
    "    def __init__(self, npoint, radius_list, nsample_list, in_channel, mlp_list):\n",
    "        super(Pointnet_SA_MSG_module, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius_list = radius_list\n",
    "        self.nsample_list = nsample_list\n",
    "\n",
    "        assert len(self.radius_list) == len(self.nsample_list)\n",
    "\n",
    "        self.in_channel = in_channel\n",
    "        self.sequentials = nn.ModuleList()\n",
    "        for sid, mlp in enumerate(mlp_list):\n",
    "            seq = nn.Sequential()\n",
    "            self.in_channel = in_channel + 3\n",
    "            for mid, out_channel in enumerate(mlp):\n",
    "                m = conv_bn(self.in_channel, out_channel, 1)\n",
    "                seq.add_module(str(mid), m)\n",
    "                self.in_channel = out_channel\n",
    "            self.sequentials.append(seq)\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: the shape is [B, N, 3]\n",
    "            points: the shape is [B, N, D]\n",
    "        Return:\n",
    "            new_xyz: the shape is [B, Np, 3]\n",
    "            new_ points: the shape is [B, Np, D']\n",
    "        \"\"\"\n",
    "        (B, N, C), Np = xyz.shape, self.npoint\n",
    "        new_xyz = self.index_points(xyz, self.farthest_point_sample(xyz, Np))  # B, Np, C\n",
    "        cat_new_points = []\n",
    "        for i, radius in enumerate(self.radius_list):\n",
    "            grouped_idx = self.ball_query(radius, self.nsample_list[i], xyz, new_xyz)  # B, Np, Ns\n",
    "            grouped_xyz = self.index_points(xyz, grouped_idx)\n",
    "            grouped_xyz -= new_xyz.view(B, Np, 1, C)  # B, Np, Ns , C\n",
    "            if points is None:\n",
    "                grouped_points = grouped_xyz  # B, Np, Ns, C\n",
    "            else:\n",
    "                grouped_points = self.index_points(points, grouped_idx)  # B, Np, Ns, D\n",
    "                grouped_points = torch.cat([grouped_xyz, grouped_points], dim=-1)  # B, Np, Ns, C+D\n",
    "\n",
    "            grouped_points = grouped_points.permute(0, 3, 2, 1).contiguous()\n",
    "            new_points = self.sequentials[i](grouped_points)\n",
    "            new_points = torch.max(new_points, 2)[0]  # B, D', Np\n",
    "            cat_new_points.append(new_points)\n",
    "        new_points = torch.cat(cat_new_points, dim=1).permute(0, 2, 1).contiguous()  # B, Np, D'\n",
    "        return new_xyz, new_points\n",
    "\n",
    "\n",
    "class PointSIFT_module_basic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointSIFT_module_basic, self).__init__()\n",
    "\n",
    "    def index_points(self, points, idx):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            this function select the specific points from the whole points according to the idx.\n",
    "        Input:\n",
    "            points: input points data, [B, N, C]\n",
    "            idx: sample index data, [B, D1, D2, ..., Dn]\n",
    "        Return:\n",
    "            new_points:, indexed points data, [B, D1, D2, ..., Dn, C]\n",
    "        \"\"\"\n",
    "        device = points.device\n",
    "        B = points.shape[0]\n",
    "        view_shape = list(idx.shape)\n",
    "        view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "        repeat_shape = list(idx.shape)\n",
    "        repeat_shape[0] = 1\n",
    "        batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "        new_points = points[batch_indices, idx, :]\n",
    "        return new_points\n",
    "\n",
    "    def pointsift_select_c(self, radius, xyz):\n",
    "        \"\"\"\n",
    "        code by c/c++ logic\n",
    "        :param radius:\n",
    "        :param xyz:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        Dist = lambda x, y, z: x ** 2 + y ** 2 + z ** 2\n",
    "        B, N, _ = xyz.shape\n",
    "        idx = torch.empty(B, N, 8)\n",
    "        judge_dist = radius ** 2\n",
    "        temp_dist = torch.ones(B, N, 8) * 1e10\n",
    "        for b in range(B):\n",
    "            for n in range(N):\n",
    "                idx[b, n, :] = n\n",
    "                x, y, z = xyz[b, n]\n",
    "                for p in range(N):\n",
    "                    if p == n: continue\n",
    "                    tx, ty, tz = xyz[b, p]\n",
    "                    dist = Dist(x - tx, y - ty, z - tz)\n",
    "                    if dist > judge_dist: continue\n",
    "                    _x, _y, _z = tx > x, ty > y, tz > z\n",
    "                    temp_idx = (_x * 4 + _y * 2 + _z).int()\n",
    "                    if dist < temp_dist[b, n, temp_idx]:\n",
    "                        idx[b, n, temp_idx] = p\n",
    "                        temp_dist[b, n, temp_idx] = dist\n",
    "        return idx.int()\n",
    "\n",
    "    def pointsift_select(self, radius, xyz):\n",
    "        \"\"\"\n",
    "        code by python matrix logic\n",
    "        :param radius:\n",
    "        :param xyz:\n",
    "        :return: idx\n",
    "        \"\"\"\n",
    "        dev = xyz.device\n",
    "        B, N, _ = xyz.shape\n",
    "        judge_dist = radius ** 2\n",
    "        idx = torch.arange(N).repeat(8, 1).permute(1, 0).contiguous().repeat(B, 1, 1).to(dev)\n",
    "        for n in range(N):\n",
    "            distance = torch.ones(B, N, 8).to(dev) * 1e10\n",
    "            distance[:, n, :] = judge_dist\n",
    "            centroid = xyz[:, n, :].view(B, 1, 3).to(dev)\n",
    "            dist = torch.sum((xyz - centroid) ** 2, -1)  # shape: (B, N)\n",
    "            subspace_idx = torch.sum((xyz - centroid + 1).int() * torch.tensor([4, 2, 1], dtype=torch.int, device=dev),\n",
    "                                     -1)\n",
    "            for i in range(8):\n",
    "                mask = (subspace_idx == i) & (dist > 1e-10) & (dist < judge_dist)  # shape: (B, N)\n",
    "                distance[..., i][mask] = dist[mask]\n",
    "                idx[:, n, i] = torch.min(distance[..., i], dim=-1)[1]\n",
    "        return idx\n",
    "\n",
    "    def pointsift_group(self, radius, xyz, points, use_xyz=True):\n",
    "\n",
    "        B, N, C = xyz.shape\n",
    "        assert C == 3\n",
    "        idx = self.pointsift_select(radius, xyz)  # B, N, 8\n",
    "\n",
    "        grouped_xyz = self.index_points(xyz, idx)  # B, N, 8, 3\n",
    "        grouped_xyz -= xyz.view(B, N, 1, 3)\n",
    "        if points is not None:\n",
    "            grouped_points = self.index_points(points, idx)\n",
    "            if use_xyz:\n",
    "                grouped_points = torch.cat([grouped_xyz, grouped_points], dim=-1)\n",
    "        else:\n",
    "            grouped_points = grouped_xyz\n",
    "        return grouped_xyz, grouped_points, idx\n",
    "\n",
    "    def pointsift_group_with_idx(self, idx, xyz, points, use_xyz=True):\n",
    "\n",
    "        B, N, C = xyz.shape\n",
    "        grouped_xyz = self.index_points(xyz, idx)  # B, N, 8, 3\n",
    "        grouped_xyz -= xyz.view(B, N, 1, 3)\n",
    "        if points is not None:\n",
    "            grouped_points = self.index_points(points, idx)\n",
    "            if use_xyz:\n",
    "                grouped_points = torch.cat([grouped_xyz, grouped_points], dim=-1)\n",
    "        else:\n",
    "            grouped_points = grouped_xyz\n",
    "        return grouped_xyz, grouped_points\n",
    "\n",
    "\n",
    "class PointSIFT_module(PointSIFT_module_basic):\n",
    "\n",
    "    def __init__(self, radius, output_channel):\n",
    "        super(PointSIFT_module, self).__init__()\n",
    "        self.radius = radius\n",
    "        self.conv1 = nn.Sequential(\n",
    "            conv_bn(3, output_channel, [1, 2], [1, 2]),\n",
    "            conv_bn(output_channel, output_channel, [1, 2], [1, 2]),\n",
    "            conv_bn(output_channel, output_channel, [1, 2], [1, 2])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "\n",
    "class PointSIFT_res_module(PointSIFT_module_basic):\n",
    "\n",
    "    def __init__(self, radius, output_channel, extra_input_channel=0, merge='add', same_dim=False):\n",
    "        super(PointSIFT_res_module, self).__init__()\n",
    "        self.radius = radius\n",
    "        self.merge = merge\n",
    "        self.same_dim = same_dim\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            conv_bn(3 + extra_input_channel, output_channel, [1, 2], [1, 2]),\n",
    "            conv_bn(output_channel, output_channel, [1, 2], [1, 2]),\n",
    "            conv_bn(output_channel, output_channel, [1, 2], [1, 2])\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            conv_bn(3 + output_channel, output_channel, [1, 2], [1, 2]),\n",
    "            conv_bn(output_channel, output_channel, [1, 2], [1, 2]),\n",
    "            conv_bn(output_channel, output_channel, [1, 2], [1, 2], activation=None)\n",
    "        )\n",
    "        if same_dim:\n",
    "            self.convt = nn.Sequential(\n",
    "                nn.Conv1d(extra_input_channel, output_channel, 1),\n",
    "                nn.BatchNorm1d(output_channel),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        _, grouped_points, idx = self.pointsift_group(self.radius, xyz, points)  # [B, N, 8, 3], [B, N, 8, 3 + C]\n",
    "\n",
    "        grouped_points = grouped_points.permute(0, 3, 1, 2).contiguous()  # B, C, N, 8\n",
    "        ##print(grouped_points.shape)\n",
    "        new_points = self.conv1(grouped_points)\n",
    "        ##print(new_points.shape)\n",
    "        new_points = new_points.squeeze(-1).permute(0, 2, 1).contiguous()\n",
    "\n",
    "        _, grouped_points = self.pointsift_group_with_idx(idx, xyz, new_points)\n",
    "        grouped_points = grouped_points.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        ##print(grouped_points.shape)\n",
    "        new_points = self.conv2(grouped_points)\n",
    "\n",
    "        new_points = new_points.squeeze(-1)\n",
    "\n",
    "        if points is not None:\n",
    "            points = points.permute(0, 2, 1).contiguous()\n",
    "            # print(points.shape)\n",
    "            if self.same_dim:\n",
    "                points = self.convt(points)\n",
    "            if self.merge == 'add':\n",
    "                new_points = new_points + points\n",
    "            elif self.merge == 'concat':\n",
    "                new_points = torch.cat([new_points, points], dim=1)\n",
    "\n",
    "        new_points = F.relu(new_points)\n",
    "        new_points = new_points.permute(0, 2, 1).contiguous()\n",
    "\n",
    "        return xyz, new_points\n",
    "\n",
    "\n",
    "# ------------------------ models ------------------------ #\n",
    "class PointNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        input: B x N x 3\n",
    "        output: B x 40\n",
    "        '''\n",
    "        super(PointNet, self).__init__()\n",
    "\n",
    "        from config.config_pointnet import config\n",
    "        self.num_point = config.num_point\n",
    "        self.num_classes = config.num_classes\n",
    "        self.K = config.K\n",
    "\n",
    "        self.input_transform_net = Input_transform_net(config)\n",
    "        self.feat_transform_net = Feature_transform_net(config, self.K)\n",
    "        self.conv1 = conv_bn(1, 64, [1, 3])\n",
    "        self.conv2 = conv_bn(64, self.K, [1, 1])\n",
    "        self.conv3 = conv_bn(self.K, 64, [1, 1])\n",
    "        self.conv4 = conv_bn(64, 128, [1, 1])\n",
    "        self.conv5 = conv_bn(128, 1024, [1, 1])\n",
    "        self.fc1 = fc_bn(1024, 512)\n",
    "        self.fc2 = fc_bn(512, 256)\n",
    "        self.fc3 = nn.Linear(256, self.num_classes)\n",
    "\n",
    "        # self.I = nn.Parameter(torch.tensor(np.eye(config.K), dtype=torch.float, requires_grad=False), requires_grad=False)\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B = x.size()[0]\n",
    "        input_transform = self.input_transform_net(x)\n",
    "        x = torch.matmul(x, input_transform)\n",
    "        x = x.view((B, 1) + x.size()[1:])\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        from config.config_pointnet import config\n",
    "        feat_transform = self.feat_transform_net(x)\n",
    "        config.end_point['transform'] = feat_transform\n",
    "\n",
    "        x = x.squeeze(3).permute(0, 2, 1).contiguous()\n",
    "        x = torch.matmul(x, feat_transform)\n",
    "        x = x.permute(0, 2, 1).contiguous()  # 这里用转置感觉有问题，后面再仔细思考一下\n",
    "        x = x.view(x.size() + (1,))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # Npymmetric function: max pooling\n",
    "        x = F.max_pool2d(x, [self.num_point, 1])\n",
    "        x = x.view([B, -1])\n",
    "        x = self.fc1(x)\n",
    "        x = F.dropout(x, p=0.3)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, p=0.3)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def get_loss(input, target):\n",
    "\n",
    "        \"\"\"\n",
    "            input: B*NUM_CLANpNpENp,\n",
    "            target: B,\n",
    "        \"\"\"\n",
    "\n",
    "        classify_loss = nn.CrossEntropyLoss()\n",
    "        loss = classify_loss(input, target)\n",
    "        assert len(loss.size()) < 2\n",
    "\n",
    "        # Enforce the transformation as orthogonal matrix\n",
    "        from config.config_pointnet import config\n",
    "        transform = config.end_point['transform']  # BxKxK\n",
    "        mat_diff = torch.matmul(transform, transform.transpose(2, 1).contiguous())\n",
    "\n",
    "        I = mat_diff.new_tensor(torch.eye(config.K))\n",
    "        mat_diff.sub_(I)\n",
    "\n",
    "        mat_diff_loss = torch.sum(mat_diff ** 2) / 2\n",
    "\n",
    "        reg_weight = 0.001\n",
    "        return loss.to(mat_diff_loss.device) + mat_diff_loss * reg_weight\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class PointNet_plus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNet_plus, self).__init__()\n",
    "        from config.config_pointnet_plus import config\n",
    "        self.num_classes = config.num_classes\n",
    "\n",
    "        # set abstraction network\n",
    "        self.pointnet_sa_msg_m1 = Pointnet_SA_MSG_module(npoint=512, radius_list=[0.1, 0.2, 0.4],\n",
    "                                                         nsample_list=[16, 32, 128], in_channel=3 - 3,\n",
    "                                                         mlp_list=[[32, 32, 64], [64, 64, 128], [64, 96, 128]])\n",
    "        self.pointnet_sa_msg_m2 = Pointnet_SA_MSG_module(npoint=128, radius_list=[0.2, 0.4, 0.8],\n",
    "                                                         nsample_list=[32, 64, 128], in_channel=323 - 3,\n",
    "                                                         mlp_list=[[64, 64, 128], [128, 128, 256], [128, 128, 256]])\n",
    "        self.pointnet_sa_m3 = Pointnet_SA_module(npoint=None, radius=None, nsample=None,\n",
    "                                                 in_channel=640, mlp=[256, 512, 1024], group_all=True)\n",
    "\n",
    "        # fully conntected network\n",
    "        self.fc1 = fc_bn(1024, 512)\n",
    "        self.dp1 = nn.Dropout(0.4)\n",
    "        self.fc2 = fc_bn(512, 256)\n",
    "        self.dp2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(256, self.num_classes)\n",
    "\n",
    "    def forward(self, xyz, points=None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: is the raw point cloud(B * N * 3)\n",
    "        Return:\n",
    "        \"\"\"\n",
    "        B = xyz.size()[0]\n",
    "        # #print('xyz:', xyz.shape)\n",
    "        l1_xyz, l1_points = self.pointnet_sa_msg_m1(xyz, points)\n",
    "        # #print('l1_xyz:{}, l1_points:{}'.format(l1_xyz.shape, l1_points.shape))\n",
    "        l2_xyz, l2_points = self.pointnet_sa_msg_m2(l1_xyz, l1_points)\n",
    "        # #print('l2_xyz:{}, l2_points:{}'.format(l2_xyz.shape, l2_points.shape))\n",
    "        l3_xyz, l3_points = self.pointnet_sa_m3(l2_xyz, l2_points)\n",
    "        # print('l3_xyz:{}, l3_points:{}'.format(l3_xyz.shape, l3_points.shape))\n",
    "        x = l3_points.view(B, 1024)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # def input_split(self, x):\n",
    "    #     features = None\n",
    "    #     if x.size(-1) > 3:\n",
    "    #         features = x[..., 3:].transpose(1, 2).contiguous()\n",
    "    #     x = x[..., 0:3].contiguous()\n",
    "    #     return x, features\n",
    "\n",
    "    @staticmethod\n",
    "    def get_loss(input, target):\n",
    "        classify_loss = nn.CrossEntropyLoss()\n",
    "        loss = classify_loss(input, target)\n",
    "        return loss\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class PointSIFT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointSIFT, self).__init__()\n",
    "\n",
    "        from config.config_pointsift import config\n",
    "        self.num_point = config.num_point\n",
    "        self.num_classes = config.num_classes\n",
    "\n",
    "        self.pointsift_res_m1 = PointSIFT_res_module(radius=0.1, output_channel=64, merge='concat')\n",
    "        self.pointnet_sa_m1 = Pointnet_SA_module(npoint=1024, radius=0.1, nsample=32, in_channel=64, mlp=[64, 128],\n",
    "                                                 group_all=False)\n",
    "\n",
    "        self.pointsift_res_m2 = PointSIFT_res_module(radius=0.25, output_channel=128, extra_input_channel=128)\n",
    "        self.pointnet_sa_m2 = Pointnet_SA_module(npoint=256, radius=0.2, nsample=32, in_channel=128, mlp=[128, 256],\n",
    "                                                 group_all=False)\n",
    "\n",
    "        self.pointsift_res_m3_1 = PointSIFT_res_module(radius=0.5, output_channel=256, extra_input_channel=256)\n",
    "        self.pointsift_res_m3_2 = PointSIFT_res_module(radius=0.5, output_channel=512, extra_input_channel=256,\n",
    "                                                       same_dim=True)\n",
    "\n",
    "        self.pointnet_sa_m3 = Pointnet_SA_module(npoint=64, radius=0.4, nsample=32, in_channel=512, mlp=[512, 1024],\n",
    "                                                 group_all=True)\n",
    "\n",
    "        self.convt = nn.Sequential(\n",
    "            nn.Conv1d(512 + 256, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # fully conntected network\n",
    "        self.fc1 = fc_bn(1024, 512)\n",
    "        self.dp1 = nn.Dropout(0.4)\n",
    "        self.fc2 = fc_bn(512, 256)\n",
    "        self.dp2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(256, self.num_classes)\n",
    "\n",
    "    def forward(self, xyz, points=None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: is the raw point cloud(B * N * 3)\n",
    "        Return:\n",
    "        \"\"\"\n",
    "        B = xyz.size()[0]\n",
    "        # #print('xyz:', xyz.shape)\n",
    "\n",
    "        # ---- c1 ---- #\n",
    "        l1_xyz, l1_points = self.pointsift_res_m1(xyz, points)\n",
    "        # print('l1_xyz:{}, l1_points:{}'.format(l1_xyz.shape, l1_points.shape))\n",
    "        c1_xyz, c1_points = self.pointnet_sa_m1(l1_xyz, l1_points)\n",
    "        # print('c1_xyz:{}, c1_points:{}'.format(c1_xyz.shape, c1_points.shape))\n",
    "\n",
    "        # ---- c2 ---- #\n",
    "        l2_xyz, l2_points = self.pointsift_res_m2(c1_xyz, c1_points)\n",
    "        # print('l2_xyz:{}, l2_points:{}'.format(l2_xyz.shape, l2_points.shape))\n",
    "        c2_xyz, c2_points = self.pointnet_sa_m2(l2_xyz, l2_points)\n",
    "        # print('c2_xyz:{}, c2_points:{}'.format(c2_xyz.shape, c2_points.shape))\n",
    "\n",
    "        # ---- c3 ---- #\n",
    "        l3_1_xyz, l3_1_points = self.pointsift_res_m3_1(c2_xyz, c2_points)\n",
    "        # print('l3_1_xyz:{}, l3_1_points:{}'.format(l3_1_xyz.shape, l3_1_points.shape))\n",
    "        l3_2_xyz, l3_2_points = self.pointsift_res_m3_2(l3_1_xyz, l3_1_points)\n",
    "        # print('l3_2_xyz:{}, l3_2_points:{}'.format(l3_2_xyz.shape, l3_2_points.shape))\n",
    "\n",
    "        l3_points = torch.cat([l3_1_points, l3_2_points], dim=-1)\n",
    "        l3_points = l3_points.permute(0, 2, 1).contiguous()\n",
    "        l3_points = self.convt(l3_points)\n",
    "        l3_points = l3_points.permute(0, 2, 1).contiguous()\n",
    "        l3_xyz = l3_2_xyz\n",
    "        # print('l3_xyz:{}, l3_points:{}'.format(l3_xyz.shape, l3_points.shape))\n",
    "\n",
    "        # ---- c4 ---- #\n",
    "        c4_xyz, c4_points = self.pointnet_sa_m3(l3_xyz, l3_points)\n",
    "        # print(c4_points.shape)\n",
    "\n",
    "        x = c4_points.view(B, 1024)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def get_loss(input, target):\n",
    "        classify_loss = nn.CrossEntropyLoss()\n",
    "        loss = classify_loss(input, target)\n",
    "        return loss\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class PointSIFT_Seg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointSIFT_Seg, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def get_loss(self):\n",
    "        pass\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # from config.config_pointnet import config\n",
    "    #\n",
    "    # net = PointNet()\n",
    "    # # #print(net)\n",
    "    # x = torch.Tensor(config.batch_size, 2048, 3)\n",
    "    # y = net(x)\n",
    "    # #print(y.size())\n",
    "    # net = PointNet_plus()\n",
    "    # xyz = torch.rand(config.batch_size, config.num_point, 3)\n",
    "    #\n",
    "    # out = net(xyz)\n",
    "    # # #print(out.shape)\n",
    "\n",
    "    m = PointSIFT()\n",
    "    xyz = torch.rand(5, 1048, 3)\n",
    "    out = m(xyz, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
